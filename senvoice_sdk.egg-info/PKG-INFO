Metadata-Version: 2.1
Name: senvoice-sdk
Version: 0.3.1
Summary: SenVoice SDK - Python SDK for Wolof & French Voice Models (TTS & STT)
Home-page: https://github.com/dnaby05/senvoice-sdk
Author: Mouhamadou Naby DIA
Author-email: mouhamadounaby.dia@orange-sonatel.com
License: UNKNOWN
Project-URL: Bug Reports, https://github.com/dnaby05/senvoice-sdk/issues
Project-URL: Source, https://github.com/dnaby05/senvoice-sdk
Keywords: senvoice speech-to-text & text-to-speech sdk wolof french
Platform: UNKNOWN
Requires-Python: >=3.7
Description-Content-Type: text/markdown

# SenVoice SDK

SDK Python asynchrone pour les APIs serverless RunPod (Text-to-Speech et Speech-to-Text) avec mod√®les unifi√©s supportant le fran√ßais et le wolof.

## üöÄ Fonctionnalit√©s

- **Asynchrone** : Performances optimis√©es avec `aiohttp` et `asyncio`
- **Mod√®les unifi√©s** : TTS et ASR supportant fran√ßais et wolof automatiquement
- **Streaming audio** : Support du streaming TTS en temps r√©el avec le nouveau mod√®le Orpheus
- **D√©tection automatique de langue** : Plus besoin de sp√©cifier la langue
- **Requ√™tes concurrentes** : Jusqu'√† 2x plus rapide que les appels s√©quentiels
- **Endpoints flexibles** : Support RunPod (cloud) et endpoints locaux
- **Gestion d'erreurs robuste** : Validation compl√®te et exceptions sp√©cialis√©es
- **Context manager** : Cleanup automatique des sessions HTTP

## Installation

```bash
pip install git+https://TOKEN@github.com/dnaby/senvoice-sdk.git
```

### Requirements.txt

Pour int√©grer SenVoice dans vos projets, ajoutez cette ligne √† votre `requirements.txt` :

```txt
senvoice-sdk @ git+https://TOKEN@github.com/dnaby/senvoice-sdk.git
```

## Architecture

Le SDK SenVoice utilise 2 mod√®les unifi√©s, chacun supportant automatiquement le fran√ßais et le wolof :

1. **TTS Unifi√©** - Synth√®se vocale multilingue (fran√ßais + wolof)
2. **ASR Unifi√©** - Reconnaissance vocale multilingue (fran√ßais + wolof)

## Utilisation

### Configuration de base

```python
import asyncio
from senvoice import SenVoice

async def main():
    # Mode RunPod (cloud avec authentification)
    async with SenVoice(
        api_key="votre_api_key_runpod",
        tts_endpoint_id="endpoint-tts-unifie",
        asr_endpoint_id="endpoint-asr-unifie"
    ) as sdk:
        # Utilisation du SDK
        pass

    # Mode local (sans authentification)
    async with SenVoice(
        tts_endpoint="http://localhost:8001",
        asr_endpoint="http://localhost:8002"
    ) as sdk:
        # Utilisation du SDK
        pass

    # Mode mixte (RunPod + Local)
    async with SenVoice(
        api_key="votre_api_key_runpod",
        tts_endpoint_id="runpod-tts-unifie-id",  # RunPod
        asr_endpoint="http://localhost:8002"     # Local
    ) as sdk:
        # Utilisation du SDK
        pass

# Ex√©cution
asyncio.run(main())
```

### Text-to-Speech (TTS)

#### Synth√®se classique

```python
async with SenVoice(api_key="key", ...) as sdk:
    # Synth√®se vocale s√©quentielle (d√©tection automatique de langue)
    response_fr = await sdk.tts.synthesize("Bonjour, comment allez-vous ?")
    response_wo = await sdk.tts.synthesize("Salam naka nga deif")

    # Synth√®se vocale concurrente (2x plus rapide)
    response_fr, response_wo = await asyncio.gather(
        sdk.tts.synthesize("Bonjour, comment allez-vous ?"),
        sdk.tts.synthesize("Salam naka nga deif")
    )

    print(f"Audio fran√ßais: {len(response_fr['audio'])} chars")
    print(f"Audio wolof: {len(response_wo['audio'])} chars")
```

#### Streaming TTS (Nouveau mod√®le Orpheus)

```python
async with SenVoice(api_key="key", ...) as sdk:
    # Streaming audio en temps r√©el
    audio_stream = sdk.tts.synthesize_stream(
        text="Bonjour, ceci est un test de streaming audio",
        voice="mamito"  # Voix disponibles: mamito, tara, fatou
    )
    
    # Sauvegarder le stream audio
    with open("output.wav", "wb") as f:
        async for chunk in audio_stream:
            f.write(chunk)
    
    # Ou traiter en temps r√©el
    async for chunk in audio_stream:
        # Jouer l'audio imm√©diatement
        play_audio_chunk(chunk)
```

#### Streaming concurrent

```python
async def save_stream(stream, filename):
    with open(filename, "wb") as f:
        async for chunk in stream:
            f.write(chunk)

async with SenVoice(api_key="key", ...) as sdk:
    # Streaming concurrent avec diff√©rentes voix
    streams = [
        save_stream(sdk.tts.synthesize_stream("Texte fran√ßais", voice="mamito"), "fr_mamito.wav"),
        save_stream(sdk.tts.synthesize_stream("Texte wolof", voice="tara"), "wo_tara.wav")
    ]
    
    await asyncio.gather(*streams)
```

### Speech-to-Text (ASR)

```python
import asyncio
import base64

async with SenVoice(api_key="key", ...) as sdk:
    # Pr√©parer l'audio en base64
    with open("audio.wav", "rb") as audio_file:
        audio_data = audio_file.read()
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')

    # Transcription avec d√©tection automatique de langue
    response_fr = await sdk.asr.transcribe(audio_base64)  # D√©tecte automatiquement le fran√ßais
    response_wo = await sdk.asr.transcribe(audio_base64)  # D√©tecte automatiquement le wolof

    # Transcription concurrente de plusieurs fichiers
    results = await asyncio.gather(
        sdk.asr.transcribe(audio_base64_fr),
        sdk.asr.transcribe(audio_base64_wo)
    )

    print(f"Transcription 1: {results[0]['transcription']}")
    print(f"Transcription 2: {results[1]['transcription']}")
```

### Pipeline TTS ‚Üí ASR complet

```python
async with SenVoice(api_key="key", ...) as sdk:
    # 1. G√©n√©ration d'audio concurrent (d√©tection automatique de langue)
    tts_fr_task = sdk.tts.synthesize("Bonjour")
    tts_wo_task = sdk.tts.synthesize("Salam")

    tts_fr_resp, tts_wo_resp = await asyncio.gather(tts_fr_task, tts_wo_task)

    # 2. Transcription concurrent (d√©tection automatique de langue)
    asr_tasks = [
        sdk.asr.transcribe(tts_fr_resp['audio']),
        sdk.asr.transcribe(tts_wo_resp['audio'])
    ]

    asr_results = await asyncio.gather(*asr_tasks)

    print(f"Pipeline FR: {asr_results[0]['transcription']}")
    print(f"Pipeline WO: {asr_results[1]['transcription']}")
```

### Test de connectivit√©

```python
async with SenVoice(api_key="key", ...) as sdk:
    # Test concurrent de tous les services
    ping_results = await sdk.ping_all()

    for service, result in ping_results.items():
        if 'error' in result:
            print(f"‚ùå {service}: {result['error']}")
        else:
            print(f"‚úÖ {service}: Connected")
```

### Configuration dynamique

```python
async with SenVoice(api_key="key") as sdk:
    # Configurer les endpoints apr√®s initialisation
    sdk.configure_tts("nouveau-endpoint-tts-unifie")
    sdk.configure_asr("nouveau-endpoint-asr-unifie")

    # Tester tous les services
    ping_results = await sdk.ping_all()
```

### Streaming Audio (Mod√®le Orpheus)

Le SDK supporte maintenant le streaming audio en temps r√©el avec le nouveau mod√®le Orpheus TTS.

#### Avantages du streaming

- **Latence r√©duite** : L'audio commence √† jouer avant la fin de la g√©n√©ration
- **M√©moire optimis√©e** : Pas besoin de stocker tout l'audio en m√©moire
- **Exp√©rience utilisateur** : Feedback imm√©diat pour l'utilisateur
- **Scalabilit√©** : Meilleure gestion des textes longs

#### Voix disponibles

- `mamito` : Voix f√©minine naturelle
- `tara` : Voix f√©minine expressive  
- `fatou` : Voix f√©minine douce

#### Exemple complet de streaming

```python
import asyncio
from senvoice import SenVoice

async def stream_to_file():
    async with SenVoice(tts_endpoint="http://localhost:8000") as sdk:
        # Texte long pour d√©montrer le streaming
        long_text = """
        Ceci est un exemple de synth√®se vocale en streaming.
        L'audio est g√©n√©r√© et diffus√© en temps r√©el,
        permettant une lecture imm√©diate sans attendre
        la fin compl√®te de la g√©n√©ration.
        """
        
        # Streaming avec gestion des chunks
        chunk_count = 0
        total_bytes = 0
        
        audio_stream = sdk.tts.synthesize_stream(
            text=long_text.strip(),
            voice="mamito"
        )
        
        with open("streaming_output.wav", "wb") as f:
            async for chunk in audio_stream:
                f.write(chunk)
                chunk_count += 1
                total_bytes += len(chunk)
                print(f"Chunk {chunk_count}: {len(chunk)} bytes")
        
        print(f"Streaming termin√©: {chunk_count} chunks, {total_bytes} bytes")

# Ex√©cution
asyncio.run(stream_to_file())
```

#### Streaming concurrent

```python
async def concurrent_streaming():
    async with SenVoice(tts_endpoint="http://localhost:8000") as sdk:
        
        async def save_stream(text, voice, filename):
            stream = sdk.tts.synthesize_stream(text=text, voice=voice)
            with open(filename, "wb") as f:
                async for chunk in stream:
                    f.write(chunk)
            return filename
        
        # Lancer plusieurs streams en parall√®le
        tasks = [
            save_stream("Texte fran√ßais", "mamito", "fr_mamito.wav"),
            save_stream("Texte wolof", "tara", "wo_tara.wav"),
            save_stream("Long texte", "fatou", "long_fatou.wav")
        ]
        
        files = await asyncio.gather(*tasks)
        print(f"Fichiers g√©n√©r√©s: {files}")

asyncio.run(concurrent_streaming())
```

### Utilisation sans context manager

Le context manager `async with` n'est pas obligatoire. Voici les alternatives :

```python
# Initialisation simple
sdk = SenVoice(
    api_key="your_key",
    tts_endpoint_id="endpoint_id",
    asr_endpoint_id="asr_endpoint_id"
)

try:
    # Utilisation normale (d√©tection automatique de langue)
    response = await sdk.tts.synthesize("Hello")
    print(f"Audio: {len(response['audio'])} chars")

    # Tests concurrents
    results = await asyncio.gather(
        sdk.tts.synthesize("Bonjour"),
        sdk.tts.synthesize("Salam")
    )

finally:
    # ‚ö†Ô∏è OBLIGATOIRE : Fermer les sessions HTTP
    await sdk.close()
```

‚ö†Ô∏è **Important** : Sans context manager, vous **devez** appeler `await sdk.close()` pour √©viter les fuites de ressources HTTP.

## Gestion des erreurs

Le SDK inclut une gestion d'erreurs compl√®te avec exceptions sp√©cialis√©es :

```python
from senvoice import SenVoice, AuthenticationError, APIError, ValidationError

async def safe_usage():
    try:
        async with SenVoice(api_key="key", ...) as sdk:
            response = await sdk.tts.synthesize("Hello")
    except AuthenticationError as e:
        print(f"Erreur d'authentification: {e}")
    except APIError as e:
        print(f"Erreur API: {e}")
    except ValidationError as e:
        print(f"Erreur de validation: {e}")
```

## Exemples d'utilisation avanc√©e

### Traitement concurrent de masse

```python
async def process_texts_concurrent(sdk, texts):
    """Traite plusieurs textes en parall√®le (d√©tection automatique de langue)"""
    tasks = [sdk.tts.synthesize(text) for text in texts]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"Erreur pour '{texts[i]}': {result}")
        else:
            print(f"‚úÖ '{texts[i]}' ‚Üí {len(result['audio'])} chars")
```

### Monitoring et retry

```python
import asyncio
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
async def robust_synthesize(sdk, text):
    """Synth√®se avec retry automatique (d√©tection automatique de langue)"""
    return await sdk.tts.synthesize(text)

async def monitor_performance(sdk):
    """Monitoring des performances en temps r√©el"""
    import time

    start = time.time()
    results = await asyncio.gather(
        sdk.ping_all(),
        sdk.tts.synthesize("Test fran√ßais"),
        sdk.tts.synthesize("Test wolof")
    )
    duration = time.time() - start

    print(f"3 op√©rations en {duration:.2f}s")
    return results
```

## Fonctionnalit√©s cl√©s

### ‚úÖ **Endpoints flexibles**

- **RunPod (cloud)** : Authentification Bearer token, URLs automatiques
- **Local** : Aucune authentification, URLs directes
- **Mode mixte** : Combinaison RunPod + Local selon vos besoins

### ‚úÖ **Mod√®les unifi√©s multilingues**

- D√©tection automatique de langue (fran√ßais/wolof)
- Plus besoin de sp√©cifier la langue
- Validation automatique des param√®tres

### ‚úÖ **Architecture modulaire asynchrone**

- 2 mod√®les unifi√©s avec leurs propres endpoints
- Sessions HTTP r√©utilis√©es pour les performances
- Context manager pour cleanup automatique

### ‚úÖ **Performance optimis√©e**

- Requ√™tes concurrentes avec `asyncio.gather()`
- Sessions aiohttp persistantes
- Benchmark int√©gr√© dans les exemples

### ‚úÖ **Interface intuitive**

```python
async with SenVoice(api_key="key", ...) as sdk:
    # S√©quentiel (d√©tection automatique de langue)
    result1 = await sdk.tts.synthesize("Bonjour")
    result2 = await sdk.tts.synthesize("Salam")

    # Concurrent (plus rapide)
    result1, result2 = await asyncio.gather(
        sdk.tts.synthesize("Bonjour"),
        sdk.tts.synthesize("Salam")
    )
    
    # Streaming en temps r√©el (nouveau mod√®le Orpheus)
    audio_stream = sdk.tts.synthesize_stream("Texte long...", voice="mamito")
    async for chunk in audio_stream:
        play_audio_chunk(chunk)  # Lecture imm√©diate
```

---

**SenVoice SDK** - D√©velopp√© pour les applications vocales s√©n√©galaises avec support natif du fran√ßais et du wolof. üá∏üá≥


